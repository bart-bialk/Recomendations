{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-26T17:30:59.369876Z",
     "start_time": "2025-06-26T17:30:58.744332Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# coo_matrix efektywny format rzadkich macierzy\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import json\n",
    "\n",
    "#Zarządzanie pamięcią\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import *\n",
    "\n",
    "from utils import calculate_map_at_k\n",
    "\n",
    "# Ustawienie liczby wątków cpu na 1 dla stabliności treningu\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bart_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:30:59.702293Z",
     "start_time": "2025-06-26T17:30:59.405349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_interactions_per_user(train_df):\n",
    "    interactions = train_df.groupby('user_id')['item_id'].count()\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(interactions, bins=50, color=\"purple\", log=True)\n",
    "    plt.xlabel(\"Liczba interakcji\")\n",
    "    plt.ylabel(\"Liczba użytkowników (log)\")\n",
    "    plt.title(\"Rozkład interakcji na użytkownika\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"interactions_per_user.png\")\n",
    "    plt.close()\n"
   ],
   "id": "8c10c89ff26c755b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:30:59.853423Z",
     "start_time": "2025-06-26T17:30:59.848010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_most_popular_items(train_df):\n",
    "    popular_items = train_df.groupby('item_id')['rating'].count().sort_values(ascending=False).head(10)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.barh([str(item) for item in popular_items.index[::-1]], popular_items.values[::-1], color=\"skyblue\")\n",
    "    plt.xlabel(\"Liczba ocen\")\n",
    "    plt.title(\"Top 10 najczęściej ocenianych przedmiotów (cold start)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"cold_start_popular_items.png\")\n",
    "    plt.close()\n"
   ],
   "id": "580190a548d910cd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:30:59.870787Z",
     "start_time": "2025-06-26T17:30:59.865795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_prepare_data():\n",
    "    print(\"[ETAP 1/3] Wczytywanie i przetwarzanie danych\")\n",
    "\n",
    "    # Wczytanie danych z plików CSV.\n",
    "    train_data_frame = pd.read_csv(TRAIN_PATH)\n",
    "    test_data_frame = pd.read_csv(TEST_PATH)\n",
    "\n",
    "    # Zliczamy unikalnych użytkowników z train i test dla nowej macierzy\n",
    "    unique_users = np.unique(np.concatenate([train_data_frame['user_id'].unique(), test_data_frame['user_id'].unique()]))\n",
    "\n",
    "    # Zliczamy unikalne przedmioty z train dla nowej macierz\n",
    "    unique_items = train_data_frame['item_id'].unique()\n",
    "\n",
    "    # Towrzymy odpowiedniej wymiary nowej macierz\n",
    "    num_users = len(unique_users)\n",
    "    num_items = len(unique_items)\n",
    "\n",
    "    # Utworzenie zmapowanych id itemtów i userów (łatwiejsze liczenie w macierzy) od 0 do N a nie od 0 , 1 ,2 , 8 , 30\n",
    "    user_to_idx = {user: i for i, user in enumerate(unique_users)}\n",
    "    item_to_idx = {item: i for i, item in enumerate(unique_items)}\n",
    "\n",
    "    idx_to_item = {i: item for item, i in item_to_idx.items()}\n",
    "\n",
    "    # Mapowanie surowych ID na ciągłe indexy w nowej macierzy\n",
    "    train_data_frame['user_idx'] = train_data_frame['user_id'].map(user_to_idx)\n",
    "    train_data_frame['item_idx'] = train_data_frame['item_id'].map(item_to_idx)\n",
    "\n",
    "    # Usunięcie wierszy, które nie mogły zostać zmapowane Pod cold start (aby nie było błędów przy czytaniu użytkowników których nie było przy treningu)\n",
    "    train_data_frame.dropna(subset=['user_idx', 'item_idx'], inplace=True)\n",
    "    train_data_frame[['user_idx', 'item_idx']] = train_data_frame[['user_idx', 'item_idx']].astype(int)\n",
    "\n",
    "    # Mapowanie końcowych ID użytkowników w danych testowych\n",
    "    test_data_frame['user_idx'] = test_data_frame['user_id'].map(user_to_idx)\n",
    "    test_data_frame.dropna(subset=['user_idx'], inplace=True)\n",
    "    test_data_frame['user_idx'] = test_data_frame['user_idx'].astype(int)\n",
    "\n",
    "    print(f\"Całkowita liczba unikalnych użytkowników (zmapowanych): {num_users}\")\n",
    "    print(f\"Całkowita liczba unikalnych przedmiotów (zmapowanych): {num_items}\")\n",
    "\n",
    "    gc.collect() # Zwolnienie pamięci po usunięciach\n",
    "\n",
    "    # train_data_frame / test_data_frame - przetworzone stare tabele już na nowo zindexowane\n",
    "    # user_to_idx / item_to_idx - możemy odczytać orginalne ID na nowe indexy\n",
    "    # idx_to_item - z indexu na orginalne ID\n",
    "    # num_users / num_items - nasze wymiary macierzy\n",
    "\n",
    "    # Dodaj w load_and_prepare_data przed return\n",
    "    # I to dodaj również\n",
    "    visualize_interactions_per_user(train_data_frame)\n",
    "    visualize_most_popular_items(train_data_frame)\n",
    "    return train_data_frame, test_data_frame, user_to_idx, item_to_idx, idx_to_item, num_users, num_items"
   ],
   "id": "3477dc44eb618861",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:30:59.918194Z",
     "start_time": "2025-06-26T17:30:59.913336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_validate_als(params, val_users, ground_truth, user_item_matrix, user_to_idx, idx_to_item):\n",
    "\n",
    "    print(f\"Parametry: factors={params['factors']}, regularization={params['regularization']}, iterations={params['iterations']}\")\n",
    "\n",
    "    # Inicjalizujemy model ALS z parametrami z configu\n",
    "    model_als = AlternatingLeastSquares(factors=params['factors'], regularization=params['regularization'], iterations=params['iterations'], random_state=ALS_RANDOM_STATE )\n",
    "\n",
    "    # Trening modelu na naszej macierzy użytkownikowo x przedmiotowej\n",
    "    model_als.fit(user_item_matrix)\n",
    "\n",
    "    # Generujemy rekomendacje dla każdego użytkownika naszej walidacji\n",
    "    als_recommendations_val = {}\n",
    "\n",
    "    for user_raw_id in tqdm(val_users, desc=f\"Walidacja ({params['name']})\"):\n",
    "\n",
    "        user_idx = user_to_idx[user_raw_id]\n",
    "\n",
    "        # Bierzemy top 10 N rekomendacji z najwyższymi wynikami\n",
    "        recommendations_idx, _ = model_als.recommend(user_idx, user_item_matrix[user_idx], N=10, filter_already_liked_items=True)\n",
    "        # Zamieniamy indexy na surowe ID\n",
    "        als_recommendations_val[user_raw_id] = [idx_to_item[rec_idx] for rec_idx in recommendations_idx]\n",
    "\n",
    "    # Liczby MAP@10 z naszego utils\n",
    "    map_score = calculate_map_at_k(als_recommendations_val, ground_truth, k=10)\n",
    "\n",
    "    print(f\"Wynik MAP@10 dla '{params['name']}': {map_score:.5f}\")\n",
    "\n",
    "    # Zwalniamy pamięć po validacji modelu\n",
    "    del model_als\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Zwracamy wynik\n",
    "    return map_score"
   ],
   "id": "1dce35c7f08b5ee3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:30:59.945549Z",
     "start_time": "2025-06-26T17:30:59.939612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_final_model_and_predict(best_params, full_train_df, test_df, user_to_idx, idx_to_item, num_users, num_items):\n",
    "\n",
    "    print(\"\\n[ETAP 3/3 + Ostateczny trening] Trenowanie finalnego modelu i dawanie wyniku csv\")\n",
    "    print(f\"Używam parametrów: factors={best_params['factors']}, regularization={best_params['regularization']}, iterations={best_params['iterations']}\")\n",
    "\n",
    "    # Budowanie pełnej macierzy interakcji z całych danych treningowych\n",
    "    full_user_item_matrix_als = coo_matrix((full_train_df['rating'], (full_train_df['user_idx'], full_train_df['item_idx'])), shape=(num_users, num_items) ).tocsr()\n",
    "\n",
    "    # Inicjalizacja ostatecznego modelu ALS\n",
    "    model_als_final = AlternatingLeastSquares(factors=best_params['factors'], regularization=best_params['regularization'],iterations=best_params['iterations'], random_state=ALS_RANDOM_STATE )\n",
    "\n",
    "    #Trening modelu na naszej ostatecznej macierzy\n",
    "    model_als_final.fit(full_user_item_matrix_als)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    if not SKIP_SUBMISSION:\n",
    "        # Zapisy dla wszystkich użytkowników MAP@10\n",
    "        submission_output = {}\n",
    "\n",
    "        # Bierzemy tylko użytkowników z test\n",
    "        users_for_prediction_raw_ids = test_df['user_id'].unique()\n",
    "\n",
    "        # Lecimy po wszystkich użytkownikach\n",
    "        for user_raw_id in tqdm(users_for_prediction_raw_ids, desc=\"Generowanie csv\"):\n",
    "            # Bierzemy orginalny ID użytkownika\n",
    "            user_idx = user_to_idx.get(user_raw_id)\n",
    "\n",
    "            if user_idx is not None:\n",
    "                # Patrzymy jakie przedmioty użytkownik już widział aby nie polecisz tego samego\n",
    "                user_interactions = full_user_item_matrix_als[user_idx]\n",
    "\n",
    "                # Generujemy top 10 rekomendacji filtrując te co widział\n",
    "                recs_idx, _ = model_als_final.recommend(user_idx, user_interactions, N=10, filter_already_liked_items=True)\n",
    "                top_10_item_ids = [idx_to_item.get(rec_idx, 0) for rec_idx in recs_idx]\n",
    "\n",
    "                # Upewniamy się że na pewno jest to 10 ocen przedmiotów\n",
    "                if len(top_10_item_ids) < 10:\n",
    "                    top_10_item_ids.extend([0] * (10 - len(top_10_item_ids)))\n",
    "\n",
    "                # Zapisujemy plik\n",
    "                submission_output[user_raw_id] = \" \".join(map(str, top_10_item_ids))\n",
    "\n",
    "                # Jeśli nie ma użytkownika odpalamy cold start\n",
    "            else: submission_output[user_raw_id] = DEFAULT_COLD_START_PREDICTIONS\n",
    "\n",
    "        # Tworzymy i zapisujemy nowy plik subbmision według wzoru\n",
    "        submission_df_final = pd.DataFrame({'user_id': users_for_prediction_raw_ids})\n",
    "        submission_df_final['predictions'] = submission_df_final['user_id'].map(submission_output)\n",
    "        submission_df_final['predictions'] = submission_df_final['predictions'].fillna(DEFAULT_COLD_START_PREDICTIONS)\n",
    "\n",
    "        submission_df_final.to_csv(SUBMISSION_FILE, index=False)\n",
    "        print(f\"\\nPlik submission zapisany do {SUBMISSION_FILE}\")\n",
    "\n",
    "    else: print(\"Generowanie pliku pominięte\")"
   ],
   "id": "d5658a207f342fa6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T17:34:51.900285Z",
     "start_time": "2025-06-26T17:30:59.961540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "\n",
    "    # Wczytujemy potrzebne dane funkcja load_and_prepare_data\n",
    "\n",
    "    train_df, test_df, user_to_idx, item_to_idx, idx_to_item, num_users, num_items = load_and_prepare_data()\n",
    "\n",
    "    # Ustawiamy najlepsze parametry na brak dla pewnosóci\n",
    "    best_params = None\n",
    "\n",
    "    # Patrzymy czy w configu wybraliśmy trening tylko jednego modelu na jednym parametrze\n",
    "    if SINGLE_MODEL_TRAINING and len(ALS_CONFIG) == 1:\n",
    "\n",
    "        # Ładujemy pierwszy element parametru (czyli jedyny)\n",
    "        best_params = ALS_CONFIG[0]\n",
    "\n",
    "        print(f\"\\n[ETAP 3/3] Trenujemy tylko jeden model z jednym zbiorem parametrów\")\n",
    "\n",
    "        # Patrzymy czy w configu mamy ustawione skipowanie validacji dla opcjonalnego przyśpieszenia treningu\n",
    "        if SKIP_VALIDATION:\n",
    "            print(\"[ETAP 2/3] Wyłączona walidacja danych\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\n[ETAP 2/3] Podział danych do walidacji\")\n",
    "\n",
    "            # Sotrujemy interakcje ocen w czasie (kolumna timestamp)\n",
    "            train_df_sorted = train_df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "            # Wcześniej wybieramy ile chcemy mieć danych do validacji (podzial danych)\n",
    "            split_point = int(len(train_df_sorted) * VALIDATION_SPLIT_RATIO)\n",
    "\n",
    "            # Rozdzielenie danych na train i validation\n",
    "            my_train_set_df = train_df_sorted.iloc[:split_point]\n",
    "            my_validation_set_df = train_df_sorted.iloc[split_point:]\n",
    "\n",
    "            # Czyścimy niepotrzebne dane których nie używamy\n",
    "            del train_df_sorted\n",
    "            gc.collect()\n",
    "\n",
    "            # ! Bierzemy użytkowników ktorzy mieli interakcje i nie mili w przedziale czasowym\n",
    "            users_in_validation_raw_ids = my_validation_set_df['user_id'].unique()\n",
    "            users_in_train_for_validation_raw_ids = my_train_set_df['user_id'].unique()\n",
    "            users_to_evaluate_raw_ids_full = np.intersect1d(users_in_validation_raw_ids, users_in_train_for_validation_raw_ids)\n",
    "\n",
    "            # Zbieramy losowe dane\n",
    "            np.random.seed(ALS_RANDOM_STATE)\n",
    "            num_users_to_sample = int(len(users_to_evaluate_raw_ids_full) * (VALIDATION_SAMPLE_PERCENT / 100.0))\n",
    "            users_to_evaluate_raw_ids = np.random.choice(users_to_evaluate_raw_ids_full, size=num_users_to_sample, replace=False)\n",
    "\n",
    "            print(f\"Zastosowano walidacje: {VALIDATION_SAMPLE_PERCENT}% użytkowników ({len(users_to_evaluate_raw_ids)} z {len(users_to_evaluate_raw_ids_full)})\")\n",
    "\n",
    "            # Mówmy jasno które elementy użytkownik ocenił\n",
    "            ground_truth_val = my_validation_set_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "            # TWORZENIE RZADKIEJ MACIERZY używając coo (bo większość komórek jest pusta) macierz kontrolna do walidacji + konwerscja na csr zoptymalizowany pod trening modelu ocen\n",
    "            user_item_matrix_for_validation = coo_matrix(\n",
    "                (my_train_set_df['rating'], (my_train_set_df['user_idx'], my_train_set_df['item_idx'])),\n",
    "                shape=(num_users, num_items) ).tocsr()\n",
    "\n",
    "            # Uruchamianie walidacji\n",
    "            map_score = train_and_validate_als(\n",
    "                params=best_params, val_users=users_to_evaluate_raw_ids, ground_truth=ground_truth_val,\n",
    "                user_item_matrix=user_item_matrix_for_validation, user_to_idx=user_to_idx, idx_to_item=idx_to_item )\n",
    "\n",
    "            print(f\"\\nWynik MAP@10 dla pojedynczego modelu: {map_score:.5f}\")\n",
    "\n",
    "    else:\n",
    "        # Proces szkolenia modelu na więcej niż jednym zbiorze parametrów\n",
    "\n",
    "        print(\"\\n[ETAP 2/3] Podział danych do walidacji\")\n",
    "\n",
    "        # Znowu chronologicznie ogarniamy dane\n",
    "        train_df_sorted = train_df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "        split_point = int(len(train_df_sorted) * VALIDATION_SPLIT_RATIO)\n",
    "\n",
    "        # Tworzenie zbioru do trenowania modelu podczas walidacji\n",
    "        my_train_set_df = train_df_sorted.iloc[:split_point]\n",
    "\n",
    "        # Tworzenie zbioru do oceny modelu na podstawie HISTORYCZNYCH danych\n",
    "        my_validation_set_df = train_df_sorted.iloc[split_point:]\n",
    "\n",
    "        del train_df_sorted\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        # Jest to po to aby rozwiązać problem z brakującymi użytkownikami którzy byli w walidacji ale w treningu i testach już nie\n",
    "\n",
    "        # Tworzenie zbiorów aby sprawdzić rekomendacje użytkowników z produktami\n",
    "        users_in_validation_raw_ids = my_validation_set_df['user_id'].unique()\n",
    "\n",
    "        # Historyczni użytkownicy dla walidacji\n",
    "        users_in_train_for_validation_raw_ids = my_train_set_df['user_id'].unique()\n",
    "\n",
    "        # Użytkownicy zarówno z dwóch zbiorów\n",
    "        users_to_evaluate_raw_ids_full = np.intersect1d(users_in_validation_raw_ids, users_in_train_for_validation_raw_ids)\n",
    "\n",
    "        np.random.seed(ALS_RANDOM_STATE)\n",
    "\n",
    "        # Wczytanie ilości użytkowników do walidacji\n",
    "        num_users_to_sample = int(len(users_to_evaluate_raw_ids_full) * (VALIDATION_SAMPLE_PERCENT / 100.0))\n",
    "\n",
    "        # Losowe wybranie użytkowników ze zbioru aby nie wybrać użytkownika jednego dwa razy\n",
    "        users_to_evaluate_raw_ids = np.random.choice(users_to_evaluate_raw_ids_full, size=num_users_to_sample, replace=False)\n",
    "\n",
    "        print(f\"Zastosowano walidacji: {VALIDATION_SAMPLE_PERCENT}% użytkowników ({len(users_to_evaluate_raw_ids)} z {len(users_to_evaluate_raw_ids_full)})\")\n",
    "\n",
    "        # Kolejna jasna prawda dla walidacji\n",
    "        ground_truth_val = my_validation_set_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "        # Macierz 0 i 1 dla interakcji albo jej braku\n",
    "        user_item_matrix_for_validation = coo_matrix( (my_train_set_df['rating'],\n",
    "        (my_train_set_df['user_idx'], my_train_set_df['item_idx'])), shape=(num_users, num_items) ).tocsr()\n",
    "\n",
    "        print(\"\\n[ETAP 3/3] Uruchamianie pętli walidacyjnej\")\n",
    "\n",
    "        # Zapisy wyników prób\n",
    "        results = []\n",
    "\n",
    "        # Śledzimy najlepsze wyniki MAP@10\n",
    "        best_map_score = -1.0\n",
    "\n",
    "        # Walidacja na podstawie parametrów z configu\n",
    "        for params in ALS_CONFIG:\n",
    "            map_score = train_and_validate_als( params=params, val_users=users_to_evaluate_raw_ids, ground_truth=ground_truth_val,\n",
    "                user_item_matrix=user_item_matrix_for_validation, user_to_idx=user_to_idx, idx_to_item=idx_to_item )\n",
    "\n",
    "            # Zapamiętanie jakie parametry były użyte\n",
    "            results.append({'params': params, 'map_score': map_score})\n",
    "\n",
    "            # Sprawdzanie czy zwalidowany model nie jest najlepszy według MAP@10\n",
    "            if map_score > best_map_score:\n",
    "                best_map_score = map_score\n",
    "                best_params = params\n",
    "                print(f\" -> Nowy najlepszy wynik MAP@10: {best_map_score:.5f} dla {params['name']} <-\")\n",
    "\n",
    "        print(\"Podsumowanie wszystkich prób:\")\n",
    "\n",
    "        # Wyświetlanie wszystkich wyników MAP@10 dla przejżystości\n",
    "        for res in results: print(f\" - {res['params']['name']}: MAP@10 = {res['map_score']:.5f}\")\n",
    "\n",
    "        # Wypisanie wyników\n",
    "        print(f\"\\nNajlepszy wynik: {best_map_score:.5f}\")\n",
    "        print(f\"Najlepsze parametry: {best_params}\")\n",
    "\n",
    "    # Patrzymy na wybrane najlepsze parametry i wtedy trenujemy najlepszy model końcowo\n",
    "    if best_params:\n",
    "        train_final_model_and_predict( best_params=best_params, full_train_df=train_df, test_df=test_df, user_to_idx=user_to_idx,\n",
    "            idx_to_item=idx_to_item, num_users=num_users, num_items=num_items )\n",
    "\n",
    "    else: print(\"Błąd z parametrami\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "id": "6b4ee791444879f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ETAP 1/3] Wczytywanie i przetwarzanie danych\n",
      "Całkowita liczba unikalnych użytkowników (zmapowanych): 868218\n",
      "Całkowita liczba unikalnych przedmiotów (zmapowanych): 76747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bart_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 20 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ETAP 3/3] Trenujemy tylko jeden model z jednym zbiorem parametrów\n",
      "[ETAP 2/3] Wyłączona walidacja danych\n",
      "\n",
      "[ETAP 3/3 + Ostateczny trening] Trenowanie finalnego modelu i dawanie wyniku csv\n",
      "Używam parametrów: factors=15, regularization=0.001, iterations=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:05<00:00,  1.65s/it]\n",
      "Generowanie csv: 100%|██████████| 412461/412461 [02:38<00:00, 2609.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plik submission zapisany do Dane/submission.csv\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
